{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "#from keras.preprocessing.image import load_img\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "#from tensorflow.keras.utils import img_to_array, array_to_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical ,load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import keyboard\n",
    "from time import sleep\n",
    "from textblob import TextBlob\n",
    "#from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = ''\n",
    "score = 0\n",
    "bigModel = None\n",
    "\n",
    "gesture = {0:'0',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'a',11:'b',12:'c',13:'d',14:'e',15:'f',16:'g',17:'h',18:'i',19:'j',20:'k',21:'l',22:'m',23:'n',24:'o',25:'p',\n",
    "26:'q',27:'r',28:'s',29:'t',30:'u',31:'v',32:'w',33:'x',34:'y',35:'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1={0:\"0\",1:\"1\",2:\"2\",3:\"3\",4:\"4\",5:\"5\",6:\"6\",7:\"7\",8:\"8\",9:\"9\",10:\"a\",11:\"b\",12:\"c\",13:\"d\",14:\"e\",15:\"f\",16:\"g\",17:\"h\",18:\"i\",19:\"j\",20:\"k\",21:\"l\",22:\"m\",23:\"n\",24:\"o\",25:\"p\",\n",
    "26:\"q\",27:\"r\",28:\"s\",29:\"t\",30:\"u\",31:\"v\",32:\"w\",33:\"x\",34:\"y\",35:\"z\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('handsign_recognition_20epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\HK 2 2021 - 2022\\AI\\project-cuoiki\\detection.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/HK%202%202021%20-%202022/AI/project-cuoiki/detection.ipynb#ch0000004?line=9'>10</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata/anh.\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(j) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/HK%202%202021%20-%202022/AI/project-cuoiki/detection.ipynb#ch0000004?line=10'>11</a>\u001b[0m frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(filename)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/HK%202%202021%20-%202022/AI/project-cuoiki/detection.ipynb#ch0000004?line=11'>12</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(frame, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/HK%202%202021%20-%202022/AI/project-cuoiki/detection.ipynb#ch0000004?line=12'>13</a>\u001b[0m fa \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39mdetectMultiScale(gray, \u001b[39m1.1\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/HK%202%202021%20-%202022/AI/project-cuoiki/detection.ipynb#ch0000004?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m(x,y,w,h) \u001b[39min\u001b[39;00m fa:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "detector=cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "id=1\n",
    "if id == 1:\n",
    "    print(0)\n",
    "    for i in range(1,6):\n",
    "        for j in range (1,21):\n",
    "            filename = 'data/anh.'  + str(i) + '.' +str(j) + '.jpg'\n",
    "            frame = cv2.imread(filename)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            fa = detector.detectMultiScale(gray, 1.1, 5)\n",
    "            for(x,y,w,h) in fa:\n",
    "                cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0), 2)\n",
    "                if not os.path.exists('dataset'):\n",
    "                    os.makedirs('dataset')\n",
    "                cv2.imwrite('dataset/anh'  + str(i) + '.' +str(j) + '.jpg', gray[y:y+h,x:x+w])\n",
    "if id == 2:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector=cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "    sampleNum = 0\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        fa = detector.detectMultiScale(gray, 1.1, 5)\n",
    "        for(x,y,w,h) in fa:\n",
    "            cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0), 2)\n",
    "            if not os.path.exists('dataset2'):\n",
    "                os.makedirs('dataset2')\n",
    "            sampleNum+=1\n",
    "            cv2.imwrite('dataset2/anh'+str(1)+'.'+str(sampleNum)+'.jpg', gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('frame',frame)\n",
    "        if sampleNum > 19:\n",
    "            break;\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
